---
title: 数据挖掘
date: 2020-08-04 16:25:06
categories: 知识
tags: 复习
math: true
---

期末考试前复习`数据挖掘与大数据分析`课程，做一个笔记总结，也以便以后查阅。

<!--more-->

# Chapter.1 简介

https://ke.qq.com/webcourse/index.html#cid=968590&term_id=101064256&taid=32603282&lite=1&vid=5285890804313344045

## 基本概念

### 什么是大数据？

大数据指，数据量规模巨大到无法通过传统数据库和软件技术在合理时间内处理、并整理成为人类所能解读的信息的，巨量的结构化或非结构化的数据。

### 什么是数据挖掘？

广义上指，从大量数据中挖掘有趣模式和知识的过程。

## 大数据4V特征

- **Volume** 数据规模大
- **Velocity** 数据流分析要求输入输出速度快
- **Variety** 数据有很多不同形式
- **Veracity** 数据的不准确性 [需要对数据的来源和类型进行验证，需要处理数据中的噪声和异常点，还要考虑到数据的暂时性，等等综合因素影响到数据的准确性和可信度]

## 数挖主要任务

1. 分类
2. 聚类
3. 关联规则挖掘
4. 离群点检测

## KDD过程

***数据挖掘是KDD的核心！***

![kdd](kdd.png)

# Chapter.2 认识数据以及数据预处理

## 属性类型

### 分类型（Categorical）

**标称（Nominal）-（特殊：二元）**
例: ID 号、眼球颜色、邮政编码
**序数（ Ordinal ）**
例: 军阶 、 GPA、用 {tall, medium, short}表示的高

此两者一般为离散的。

### 数值型（Numerical）

**区间（Interval）**
例: 日历、摄氏或华氏温度.
**比率（Ratio）**
例: 开氏温度、长度、计数

此两者一般为连续的。

---

### 离散属性(Discrete Attribute)

**有限或无限可数个值**
例: 邮政编码、计数、文档集的词

**常表示为整数变量或字符串变量**   

### 连续属性(Continuous Attribute)

**属性值为实数**
例: 温度、高度、重量

**实践中, 实数只能用有限位数字的数度量和表示.**

**连续属性一般用浮点变量表示**

---

**二元属性(binary attributes)**

离散属性的特例
仅取两个不同值，常用0、1表示

### 对称的二元属性

两个值有同等重要性

例：性别

### 非对称的二元属性[重要!]

通常，一个值比另一个更重要
**重要的值通常比较少出现，通常用1表示**
例如，化验结果{阴性，阳性}，其中阳性较少，但更值得关注

## 数据的统计描述

### 中心性

- 均值(mean)

- 众数(mode)

  一个数据集中可能有多个众数

- 中位数(median)

  近似值估计(线性插值方法)：

  ![image-20200804232835061](image-20200804232835061.png)

- 中列数(midrange)

  **数据集的最大和最小值的平均值**

### 散度

- 极差：max-min

- 四分位数(Quantile)：3个数将数据分成四等分

- 四分位数极差：Q3-Q1的距离

- 方差

- 标准差

- 五数概括：[min,Q1,median,Q3,max]

  可以用**盒图(boxplot)**表示

## 相似性度量

### 标称属性

i与j两个对象相异度度量方法:
$$
d(i,j)=\frac{p-m}{p}\\
m：状态相同的变量数目，p：变量总数
$$
**计算二元变量的相似度：**

首先获取列联表

|           |      | 对象j |      |      |
| --------- | ---- | ----- | ---- | ---- |
|           |      | 1     | 0    | sum  |
| **对象i** | 1    | q     | r    | q+r  |
|           | 0    | s     | t    | s+t  |
|           | sum  | q+s   | r+t  | p    |

>**对称:** 二元变量的两个状态具有同等价值
>
>**不对称**: 二元变量的两个状态的输出不是同样重要

**对称**二元变量的相异度计算——简单匹配：
$$
d(i,j)=\frac{r+s}{q+r+s+t}
$$
**不对称**二元变量的相异度计算：

> ***对于非对称二元变量，负匹配数目t被忽略，即分母中删去0与0的匹配数。***

$$
d(i,j)=\frac{r+s}{q+r+s}=1-\frac{q}{q+r+s}=1-Jaccard(i,j)\\
Jaccard系数用于比较有限样本集之间的相似性，该系数越大，相似度越高。
$$



### 数值属性

常使用**距离**来度量两个数据对象之间的相异性

**闵可夫斯基(Minkowski)距离**：
$$
d(i,j)=\sqrt[q]{|x_{i1}-x_{j1}|^{q}+|x_{i2}-x_{j2}|^{q}+\cdots+|x_{ip}-x_{jp}|^{q}}\\
其中i和j是两个p-维数据对象(q为正整数)
$$
**曼哈顿(Manhattan)距离**：上式中q=1

**欧几里德(Euclidean)距离**：上式中q=2

另外距离也可以加权计算。

### 数据标准化/归一化

数据标准化：

1. 计算平均绝对偏差
   $$
   s_{f}=\frac{1}{n}(|x_{1f}-m_{f}|+|x_{2f}-m_{f}|+\cdots+|x_{nf}-m_{f}|)\\
   其中m_{f}=\frac{1}{n}(x_{1f}+x_{2f}+\cdots+x_{nf})
   $$

2. 计算标准化的度量值
   $$
   Z_{if}=\frac{x_{if}-m_{f}}{s_{f}}
   $$
   

使用**平均绝对偏差**比使用**标准差**更具有鲁棒性

数据归一化：

计算混合类型变量描述的对象的相异度的基本思想是，将不同类型的变量组合在单个相异度矩阵中, **把所有变量转换到共同的值域区间[0.0, 1.0]上** 。



- 最大最小法

$$
x'=\frac{x-x_{min}}{x_{max}-x_{min}}
$$

- z-score

$$
x'=\frac{x-\mu}{\sigma}
$$



### 其他相似性度量方式

余弦相似性（向量内积空间的夹角）
马氏距离 （考虑数据局部分布）
相关系数 （皮尔森系数） 
KL散度（数据分布比较） 

## 数据预处理

### 数据清理

- 空缺值。用平均值或相近的样本平均值或用空值替代空缺值。
- 处理噪声数据，删除孤立点。可用分箱、聚类、回归等方法处理噪声。

### 数据集成

- 冗余数据分析
  - 数值型：相关分析
  - 标称型：卡方检验
- 集成多个数据库、数据立方体或文件

**相关分析**：计算相关系数(皮尔逊系数)
$$
\begin{align}
r_{A,B}&=\frac{\sum_{i=1}^{n}(a_{i}-\overline{A})(b_{i}-\overline{B})}{(n-1)\sigma_{A}\sigma_{B}}\\
&=\frac{\sum_{i=1}^{n}(a_{i}b_{i})-n\overline{A}\overline{B}}{(n-1)\sigma_{A}\sigma_{B}}
\end{align}\\
\sigma_{A}，\sigma_{B}为各自标准差,\sum_{i=1}^{n}(a_{i}b_{i})=A\cdot B
$$
r=0不相关，r>0正相关，r<0负相关

**卡方检验[！！重要！！]**

σij是(ai,bj)的观测频度（实际计数）
eij是(ai,bj)的期望频度（单位是次数）
N是数据元组的个数
$$
\chi^2=\sum_{i=1}^c\sum_{j=1}^r\frac{(\sigma_{ij}-e_{ij})^2}{e_{ij}}\\
e_{ij}=\frac{count(A=a_{i})*count(b=b_{j})}{N}\\
自由度:(c-1)*(r-1)
$$
![chi-square](chi-square.png)

### 数据归约

- 得到数据集的压缩表示，但可以得到相同或相近的结果
- 数据归约策略：
  - 维归约:小波分析、PCA、特征筛选
  - 数量归约：回归、聚类、采样、数据立方体聚集
  - 数据压缩：使用变换

---

**特征筛选[！！] 用到信息熵**

信息熵：刻画系统的混乱程度
$$
H(X)=-\sum_{i=1}^np(x_{i})\log p(x_{i})\\p(x_i)为X出现x_i的概率
$$
条件信息熵：在已知X的基础上需要多少信息来描述Y
$$
H(Y|X)=\sum_{x\in\chi}p(x)H(Y|X=x)
$$
**信息增益**：刻画在已知X的基础上需要节约多少信息来描述Y
$$
IG(Y|X)=H(Y)-H(Y|X)
$$
特征筛选即**选择对分类变量Y信息增益大的特征**，删去信息增益小的特征。

### 数据变换

- 规范化和聚集

### 数据离散化

- 将连续数据进行离散处理