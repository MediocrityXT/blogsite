---
title: 数据挖掘
date: 2020-08-04 16:25:06
categories: 知识
tags: 复习
math: true
---

期末考试前复习`数据挖掘与大数据分析`课程，做一个笔记总结，也以便以后查阅。

<!--more-->

# Chapter.1 简介

https://ke.qq.com/webcourse/index.html#cid=968590&term_id=101064256&taid=32603282&lite=1&vid=5285890804313344045

## 基本概念

### 什么是大数据？

大数据指，数据量规模巨大到无法通过传统数据库和软件技术在合理时间内处理、并整理成为人类所能解读的信息的，巨量的结构化或非结构化的数据。

### 什么是数据挖掘？

广义上指，从大量数据中挖掘有趣模式和知识的过程。

## 大数据4V特征

- **Volume** 数据规模大
- **Velocity** 数据流分析要求输入输出速度快
- **Variety** 数据有很多不同形式
- **Veracity** 数据的不准确性 [需要对数据的来源和类型进行验证，需要处理数据中的噪声和异常点，还要考虑到数据的暂时性，等等综合因素影响到数据的准确性和可信度]

## 数挖主要任务

1. 分类
2. 聚类
3. 关联规则挖掘
4. 离群点检测

## KDD过程

***数据挖掘是KDD的核心！***

![kdd](kdd.png)

# Chapter.2 认识数据以及数据预处理

## 属性类型

### 分类型（Categorical）

**标称（Nominal）-（特殊：二元）**
例: ID 号、眼球颜色、邮政编码
**序数（ Ordinal ）**
例: 军阶 、 GPA、用 {tall, medium, short}表示的高

此两者一般为离散的。

### 数值型（Numerical）

**区间（Interval）**
例: 日历、摄氏或华氏温度.
**比率（Ratio）**
例: 开氏温度、长度、计数

此两者一般为连续的。

---

### 离散属性(Discrete Attribute)

**有限或无限可数个值**
例: 邮政编码、计数、文档集的词

**常表示为整数变量或字符串变量**   

### 连续属性(Continuous Attribute)

**属性值为实数**
例: 温度、高度、重量

**实践中, 实数只能用有限位数字的数度量和表示.**

**连续属性一般用浮点变量表示**

---

**二元属性(binary attributes)**

离散属性的特例
仅取两个不同值，常用0、1表示

### 对称的二元属性

两个值有同等重要性

例：性别

### 非对称的二元属性[重要!]

通常，一个值比另一个更重要
**重要的值通常比较少出现，通常用1表示**
例如，化验结果{阴性，阳性}，其中阳性较少，但更值得关注

## 数据的统计描述

### 中心性

- 均值(mean)

- 众数(mode)

  一个数据集中可能有多个众数

- 中位数(median)

  近似值估计(线性插值方法)：

  ![image-20200804232835061](image-20200804232835061.png)

- 中列数(midrange)

  **数据集的最大和最小值的平均值**

### 散度

- 极差：max-min

- 四分位数(Quantile)：3个数将数据分成四等分

- 四分位数极差：Q3-Q1的距离

- 方差

- 标准差

- 五数概括：[min,Q1,median,Q3,max]

  可以用**盒图(boxplot)**表示

## 相似性度量

### 标称属性

i与j两个对象相异度度量方法:
$$
\begin{gathered}
d(i,j)=\frac{p-m}{p}\\\\
m：状态相同的变量数目,p：变量总数
\end{gathered}
$$
**计算二元变量的相似度：**

首先获取列联表

|           |      | 对象j |      |      |
| --------- | ---- | ----- | ---- | ---- |
|           |      | 1     | 0    | sum  |
| **对象i** | 1    | q     | r    | q+r  |
|           | 0    | s     | t    | s+t  |
|           | sum  | q+s   | r+t  | p    |

>**对称:** 二元变量的两个状态具有同等价值
>
>**不对称**: 二元变量的两个状态的输出不是同样重要

**对称**二元变量的相异度计算——简单匹配：
$$
d(i,j)=\frac{r+s}{q+r+s+t}
$$
**不对称**二元变量的相异度计算：

> ***对于非对称二元变量，负匹配数目t被忽略，即分母中删去0与0的匹配数。***

$$
\begin{gathered}
d(i,j)=\frac{r+s}{q+r+s}=1-\frac{q}{q+r+s}=1-Jaccard(i,j)\\\\
Jaccard系数用于比较有限样本集之间的相似性，该系数越大，相似度越高。
\end{gathered}
$$



### 数值属性

常使用**距离**来度量两个数据对象之间的相异性

**闵可夫斯基(Minkowski)距离**：
$$
\begin{gathered}
d(i,j)=\sqrt[q]{|x_{i1}-x_{j1}|^{q}+|x_{i2}-x_{j2}|^{q}+\cdots+|x_{ip}-x_{jp}|^{q}}\\\\
其中i和j是两个p-维数据对象(q为正整数)
\end{gathered}
$$
**曼哈顿(Manhattan)距离**：上式中q=1

**欧几里德(Euclidean)距离**：上式中q=2

另外距离也可以加权计算。

### 数据标准化/归一化

#### 数据标准化：

1. 计算平均绝对偏差
   $$
   \begin{gathered}
   s_{f}=\frac{1}{n}(|x_{1f}-m_{f}|+|x_{2f}-m_{f}|+\cdots+|x_{nf}-m_{f}|)\\\\
   其中m_{f}=\frac{1}{n}(x_{1f}+x_{2f}+\cdots+x_{nf})
\end{gathered}
   $$
   
2. 计算标准化的度量值
   $$
   Z_{if}=\frac{x_{if}-m_{f}}{s_{f}}
   $$
   

使用**平均绝对偏差**比使用**标准差**更具有鲁棒性

#### 数据归一化[！！]：

计算混合类型变量描述的对象的相异度的基本思想是，将不同类型的变量组合在单个相异度矩阵中, **把所有变量转换到共同的值域区间[0.0, 1.0]上** 。



- 最大最小法

$$
x'=\frac{x-x_{min}}{x_{max}-x_{min}}
$$

- z-score

$$
x'=\frac{x-\mu}{\sigma}
$$



### 其他相似性度量方式

余弦相似性（向量内积空间的夹角）
马氏距离 （考虑数据局部分布）
相关系数 （皮尔森系数） 
KL散度（数据分布比较） 

## 数据预处理

### 数据清理[！！]

- 空缺值。**用平均值或相近的样本平均值或用空值替代空缺值。**
- 处理噪声数据，删除孤立点。可用分箱、聚类、回归等方法处理噪声。

### 数据集成

- 冗余数据分析
  - 数值型：相关分析
  - 标称型：卡方检验
- 集成多个数据库、数据立方体或文件

#### **相关分析**：计算相关系数(皮尔逊系数)

$$
\begin{align}
r_{A,B}&=\frac{\sum_{i=1}^{n}(a_{i}-\overline{A})(b_{i}-\overline{B})}{(n-1)\sigma_{A}\sigma_{B}}\\
&=\frac{\sum_{i=1}^{n}(a_{i}b_{i})-n\overline{A}\overline{B}}{(n-1)\sigma_{A}\sigma_{B}}\\\\
\sigma_{A}，\sigma_{B}&为各自标准差,\sum_{i=1}^{n}(a_{i}b_{i})=A\cdot B
\end{align}\\
$$
r=0不相关，r>0正相关，r<0负相关

#### **卡方检验[！！重要！！]**

σij是(ai,bj)的观测频度（实际计数）
eij是(ai,bj)的期望频度（单位是次数）
N是数据元组的个数
$$
\begin{gathered}
\chi^2=\sum_{i=1}^c\sum_{j=1}^r\frac{(\sigma_{ij}-e_{ij})^2}{e_{ij}}\\\\
e_{ij}=\frac{count(A=a_{i})*count(b=b_{j})}{N}\\\\
自由度:(c-1)*(r-1)
\end{gathered}
$$
![chi-square](chi-square.png)

### 数据归约

- 得到数据集的压缩表示，但可以得到相同或相近的结果
- 数据归约策略：
  - 维归约:小波分析、PCA、特征筛选
  - 数量归约：回归、聚类、采样、数据立方体聚集
  - 数据压缩：使用变换

---

**小波变换:**

保存小波较大的系数进行原始数据的压缩，主要用于图像分析中。

**PCA——Principal component analysis（PCA），K-L变换:**

基本思想是找到一个投影，其能表示数据的最大变化

#### **特征筛选[！！] 用到信息熵**

信息熵：刻画系统的混乱程度
$$
\begin{gathered}
H(X)=-\sum_{i=1}^np(x_{i})\log p(x_{i})\\\\
p(x_i)为X出现x_i的概率
\end{gathered}
$$
条件信息熵：在已知X的基础上需要多少信息来描述Y
$$
H(Y|X)=\sum_{x\in\chi}p(x)H(Y|X=x)
$$
**信息增益**：刻画在已知X的基础上需要节约多少信息来描述Y
$$
IG(Y|X)=H(Y)-H(Y|X)
$$
特征筛选即**选择对分类变量Y信息增益大的特征**，删去信息增益小的特征。

### 数据变换

- 规范化（归一化）和聚集

### 数据离散化

- 将连续数据进行离散处理
  - 通过将属性域划分为区间，减少给定连续属性值的个数。区间的标号可以代替实际的数据值。
- 用高层概念代替底层属性值
  - 通过使用高层的概念（比如：青年、中年、老年）来替代底层的属性值（比如：实际的年龄数据值）来规约数据。

# Chapter.3 关联规则挖掘

## 定义

- 关联规则挖掘

  - 产生频繁项集：发现满足最小支持度阈值的所有项集，这些项集称作频繁项集。
  - 产生规则：从上一步发现的频繁项集中提取**所有高置信度**的规则，这些规则称作**强规则**（strong rule）。

- 频繁模式：数据库中频繁出现的项集。

- 项集(Itemset)：包含0个或多个项的集合。包含k个项的项集称为k-项集。

- 支持度计数(Support Count)：包含特定项集的事务个数。

- 支持度(Support)：包含项集的事务数与总事务数的比值。

- 关联规则：关联规则是形如 X→Y的蕴含表达式, 其中 X 和 Y 是不相交的项集
  例子:    {Milk, Diaper} → {Beer} 

  - 支持度 support (X→Y): 确定**项集的频繁程度**。
    $$
    \begin{gathered}
    support(X\rightarrow Y)=P(X\cup Y)\\\\
    P(X\cup Y) 表示事务包含集合A和B中每个项的概率 
    \end{gathered}
    $$
    

  - 置信度confidence(X→Y)：确定**Y在包含X的事务中出现的频繁程度**。
    $$
    confidence(X\rightarrow Y)=P(X|Y)=\frac{support(X\cup Y)}{support(X)}
    $$
    

## Apriori算法

基本思想

Apriori流程和计算[！！！！]

找到强关联规则

挑战和改进

## FP-Growth算法

如何构造FP树

如何挖掘

两算法区别：

1. 范式不同。产生测试和在FP树上
2. 时间复杂度不同。FP树更快
3. 内存消耗。FP树使用内存较多
4. FP实现难度更大。

## 评估方法

支持度、置信度、兴趣因子

# Chapter.4 分类

## 基本概念

监督/无监督

生成/判别

分类/回归

## 分类算法

### 决策树

构造过程

属性选择基本准则

信息增益

### KNN

基本思想

优缺点

### SVM

支持向量/小样本 

最大间隔-有泛化能力

基本思想

非线性问题：核函数

### 其他

过拟合问题 先剪枝后剪枝

Naive Bayes 贝叶斯理论

人工神经网络 感知机 BP网络

## 集成学习

### 学习准则

准确性

多样性：多个算法组合

### 集成策略[！！]

Bagging

Boosting

Stacking

## 评估

准确率

精度

召回率

F1

当类不平衡时：灵敏度 特效性

# Chapter.5 聚类及离群点检测

## 什么是聚类

## 聚类算法分类

### Kmeans

### DBSCAN

### 其他

## 什么是离群点

## 离群点种类

## LOF

# Chapter.6 大数据分析

## 哈希技术

### Min-Hash 最小哈希

### 计算签名矩阵[！！]

### LSH 局部敏感哈希

用于近似的方式

## 数据流挖掘

### 数据流挑战 4个

### 概念漂移[！！]

### 分类

VFDT 少量数据构造动态决策树

### 聚类

线上+线下

#### 线上：数据抽象

微簇

##### [！！]簇特征(CF) 具有可加/减性 增量

#### 线下：Kmeans/DBSCAN

## Hadoop/Spark

### 什么是Hadoop/Spark

### Hadoop设计准则

### Hadoop生态

### HDFS 存储

### MapReduce 计算

### MapReduce vs Spark

### RDD 操作