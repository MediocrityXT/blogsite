---
title: KL散度=交叉熵=最大似然估计
date: 2021-06-12 10:09:03
categories: 知识
tags: 感悟

---

损失函数中常用到的KL散度、交叉熵，与最大似然估计，本质上是一样的啊！
就是希望我预测出来的与我的标注的概率分布越接近越好。

<!--more-->

比较熵、KL散度和交叉熵的数学定义会发现：
`KL散度 = 交叉熵 - 熵`

## 从编码的角度理解交叉熵

**熵**的意义是：对一个随机变量A编码所需要的**最小字节数**，也就是使用哈夫曼编码根据A的概率分布对A进行编码所需要的字节数；

**KL散度**的意义是：使用随机变量B的最优编码方式对随机变量A编码所需要的**额外字节数**，具体来说就是使用哈夫曼编码却根据B的概率分布对A进行编码，所需要的编码数比A编码所需要的最小字节数多的数量；

**交叉熵**的意义是：使用随机变量B的最优编码方式对随机变量A编码所需要的**字节数**，具体来说就是使用哈夫曼编码却根据B的概率分布对A进行编码，所需要的编码数。

在损失函数中，ground-truth当做随机变量A，这个熵是常数。

最大似然估计的公式与这种情况下的交叉熵相同。
